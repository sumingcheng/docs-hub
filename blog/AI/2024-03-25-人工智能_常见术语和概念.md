---
authors: sumingcheng
---
# 人工智能 常见术语和概念



 **Link:** [https://zhuanlan.zhihu.com/p/688818306]



| 术语 | 解释 |
| --- | --- |
| AI（人工智能） | 指模拟人类智能的技术，使机器能够执行需要人类智能的任务，如学习、推理、自我修正等。 |
| ML（机器学习） | AI的一个分支，指让机器通过数据学习并做出预测或决策的方法，而无需明确编程。 |
| DL（深度学习） | 机器学习的一个子集，使用被称为神经网络的算法，尤其是深层神经网络，从大量数据中学习。 |
| NLP（自然语言处理） | 使计算机能够理解、解释和生成人类语言的AI分支。 |
| CV（计算机视觉） | 使计算机能够从图像或多维数据中理解和解释视觉信息的科学。 |
| ANN（人工神经网络） | 由相互连接的节点或神经元组成的计算系统，模拟人脑解决问题。 |
| CNN（卷积神经网络） | 一种深度学习算法，特别适用于处理具有网格结构的数据，如图像。 |
| RNN（循环神经网络） | 一种处理序列数据的神经网络，能够利用其内部状态（记忆）处理输入序列。 |
| GAN（生成对抗网络） | 由两个神经网络组成，通过相互对抗来提高生成的数据质量。 |
| RL（强化学习） | 一种让机器通过试错来学习特定任务的最佳策略的算法。 |
| BERT（双向编码器表示从Transformer） | 一个预训练NLP模型，用于理解自然语言文本。 |
| GPT（生成预训练Transformer） | 一个自然语言处理模型，专注于生成文本。 |
| Transformer | 一种深度学习模型，广泛用于处理序列数据，尤其是在NLP领域。 |
| RAG（检索增强生成） | 结合了检索和生成的技术，用于提升自然语言生成的准确性和相关性。 |
| Zero-shot learning | 学习模型如何在没有见过任何训练数据的情况下解决任务的能力。 |
| Few-shot learning | 指让模型仅使用极少量的训练样本来学习任务的能力。 |

| 术语 | 解释 |
| --- | --- |
| LSTM（长短期记忆） | 一种特殊的RNN，能够学习长期依赖信息，常用于序列数据的处理。 |
| GRU（门控循环单元） | LSTM的一种变体，用于序列数据的建模，但结构更简单。 |
| Autoencoder | 一种无监督的神经网络，用于数据编码的有效表示。 |
| Reinforcement Learning | 一种机器学习方法，通过奖励和惩罚机制来训练模型。 |
| Supervised Learning | 一种机器学习任务，模型从标注数据中学习。 |
| Unsupervised Learning | 一种机器学习任务，模型从未标注数据中学习。 |
| Semi-supervised Learning | 介于监督学习和无监督学习之间，模型从部分标注的数据中学习。 |
| Transfer Learning | 将从一个任务学到的知识应用到另一个相关任务的方法。 |
| Federated Learning | 一种机器学习设置，模型在多个边缘设备上分布式训练，不共享数据。 |
| Attention Mechanism | 使模型能够在处理信息时，关注到更重要部分的技术。 |
| Transformer | 一种基于自注意力机制的模型架构，广泛用于处理序列数据。 |
| Sequence-to-Sequence | 一种模型架构，用于将一个序列转换为另一个序列，如机器翻译。 |
| Word Embedding | 将单词或短语从词汇表映射到向量的一种技术。 |
| Entity Recognition | 从文本中识别具有特定意义的实体（如人名、地点等）。 |
| Sentiment Analysis | 确定文本的情感倾向，如正面、负面或中性。 |
| Chatbots | 设计用于模拟人与人之间对话的AI系统。 |
| Generative Models | 能够生成新数据实例的模型，如GAN。 |
| Bias and Variance | 机器学习模型的两种主要误差来源，偏差与方差。 |
| Hyperparameter Tuning | 选择一组最优的超参数，以提高模型的性能。 |
| Cross-validation | 一种评估模型性能的技术，通过在不同的数据子集上训练和测试模型。 |
| Natural Language Understanding (NLU) | 让计算机理解、解释和生成人类语言的过程。 |
| Natural Language Generation (NLG) | 自动生成人类语言文本的过程。 |
| Object Detection | 在图像中识别对象的位置及类别的技术。 |
| Image Segmentation | 将图像分割成多个部分或对象的过程。 |
| Edge Computing | 数据在产生源头附近处理，而不是在中心或云中处理。 |

| 术语 | 解释 |
| --- | --- |
| Multi-task Learning | 一种学习策略，旨在同时解决多个相关任务，共享表示以提高效率和性能。 |
| Anomaly Detection | 识别数据集中的异常或不寻常模式的过程。 |
| Dimensionality Reduction | 减少数据集中变量数量的过程，用于提高算法效率并改善性能。 |
| Feature Engineering | 创建新的输入特征或修改现有特征以提高机器学习模型性能的过程。 |
| Ensemble Learning | 结合多个模型来改善预测性能的技术，如随机森林和梯度提升。 |
| Overfitting | 一个模型在训练数据上学得太好，以至于泛化到新数据上时性能下降。 |
| Underfitting | 模型无法在训练数据上获得足够的学习，也无法捕捉数据的基本结构。 |
| Precision and Recall | 在分类任务中，精确度和召回率是衡量模型性能的重要指标。 |
| F1 Score | 精确度和召回率的调和平均数，用于衡量模型的整体性能。 |
| Regularization | 一种减少模型过拟合的技术，通过添加一个惩罚项到损失函数。 |
| Activation Functions | 在神经网络中，激活函数决定了一个节点是否应该被激活，帮助网络学习复杂的模式。 |
| Backpropagation | 一种训练人工神经网络的算法，通过计算损失函数相对于网络参数的梯度来更新权重。 |
| Data Augmentation | 通过对原始数据进行变化生成新数据的技术，以增强模型的泛化能力。 |
| Model Deployment | 将训练好的模型部署到生产环境中，以便对新数据做出预测。 |
| Ethics in AI | 讨论和指导人工智能的发展和应用，确保技术被负责任地使用的原则和标准。 |
| Explainable AI (XAI) | 提高机器学习模型的可解释性，以便人类理解模型的决策过程。 |
| Data Imbalance | 在数据集中，一些类别的样本远多于其他类别，可能影响模型性能。 |
| Synthetic Data | 通过算法生成的数据，用于训练模型，特别是在真实数据不足或难以获取的情况下。 |
| Bias in AI | 指模型在预测时系统性偏离真实值，可能由不平衡的数据或错误的模型假设引起。 |
| Meta-learning | 也称为“学习如何学习”，旨在设计模型能够快速适应新任务的技术。 |
| Reinforcement Learning | 通过与环境的交互，采取行动以最大化某种累积奖励的学习方法。 |
| Graph Neural Networks (GNNs) | 用于处理图结构数据的神经网络，如社交网络、分子结构等。 |
| Quantum Machine Learning | 结合量子计算和机器学习，以期在特定任务上提供超越传统算法的性能。 |
| Bias-Variance Tradeoff | 描述模型复杂度与泛化能力之间的关系， |

